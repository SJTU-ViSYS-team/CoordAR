_target_: src.models.tokenizer_module.TokenizerModule

defaults:
  - tokenizer: default


optimizer: ranger
optimizer_init:
  lr_dict:
    .*: 1e-5
  weight_decay: 1e-5

# scheduler: cosine
# lr_schedule_cfg:
#   warmup_factor: 0.001
#   warmup_epochs: 1
#   warmup_method: linear
#   anneal_method: cosine
#   anneal_point: 0.72
#   steps: [0.66, 0.88]
#   target_lr_factor: 0
#   poly_power: 0.9
#   step_gamma: 0.1
  # T_0: 1
  # T_mult: 2
scheduler: one_cycle
lr_schedule_cfg:
  max_lr: ${model.optimizer_init.lr}
  steps_per_epoch: ${trainer.limit_train_batches}
  epochs: ${trainer.max_epochs}
  cycle_momentum: false
  pct_start: 0.0

train_vis_step: 1000
val_vis_step: 1000
test_vis_step: 100
preprocess_batch:
  _target_: src.data.collate_importer.FunctionImporter
  signature:  src.data.collate_importer.preprocess_batch
lr_monitor: val/loss
vis_dir: "${paths.output_dir}/vis"